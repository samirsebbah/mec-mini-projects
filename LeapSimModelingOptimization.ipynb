{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9URdyKY8cUX"
      },
      "source": [
        "## Mount google drive to pull the input data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RPrrjpjQR4z"
      },
      "source": [
        "#About\n",
        "\n",
        "In this notebook we are using Bayesian Optimization to select the most promising values for the hyper parameters of our [neural network model](https://github.com/samirsebbah/mec-mini-projects/blob/master/LeapSimModeling.ipynb).\n",
        "\n",
        "Fine-tuning these hyperparameters can significantly impact the network's ability to generalize and perform well on unseen data.\n",
        "\n",
        "Below are the hyperparameters we considered during the tuning process:\n",
        "1. Learning Rate\n",
        "2. Batch Size\n",
        "3. Number of Epochs\n",
        "4. Number of hidden layers (2 layers is the best option). Removed\n",
        "5. Number of neurons per Layer\n",
        "6. Activation function\n",
        "\n",
        "From the optimization below the best parameters' values are\n",
        "Best hyperparameters: [0.0008468986729585612, 80, 50, 369, 2, 'relu']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0dDE-G7h6LB",
        "outputId": "d3650f25-e6d2-4e1d-ec86-ba96e2c0e41a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T58IRDRM8wdr"
      },
      "source": [
        "## Import libs and setup parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "989U8ryedF0A"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from numpy import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# configs and params\n",
        "MY_SEED = 43\n",
        "TRAINING_SAMPLE_NBR_ROWS =1_000_000\n",
        "MY_COLORS = ('darkblue','darkgreen','darkred')\n",
        "\n",
        "pd.set_option('display.max_columns', None) # display all columns\n",
        "\n",
        "\n",
        "# Set Google Drive as working directory.\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "# location for the project files to be saved\n",
        "project_working_dir = \"leap_sim_project\"\n",
        "\n",
        "# input folder of dataset\n",
        "dataset_input_zip_folder = root_dir + '/Kaggle/leap-atmospheric-physics-ai-climsim.zip'\n",
        "train_data_file_name = 'train.csv'\n",
        "test_data_file_name = 'test.csv'\n",
        "submission_data_file_name = 'sample_submission.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82co4gMTVuww"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxzaZ4q1x6fk"
      },
      "source": [
        "## Helper methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84jNmr8v3bQC"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile as zipfile\n",
        "\n",
        "def create_and_set_working_directory(project_folder):\n",
        "    # check if your project folder exists. if not, it will be created.\n",
        "    if os.path.isdir(root_dir + project_folder) == False:\n",
        "        os.mkdir(root_dir + project_folder)\n",
        "        print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "    # change the OS to use your project folder as the working directory\n",
        "    os.chdir(root_dir + project_folder)\n",
        "\n",
        "create_and_set_working_directory(project_working_dir)\n",
        "\n",
        "# method to read a dataset from a zipped folder\n",
        "def read_dataset(dataset_input_zip_folder, train_data_file_name, nbr_rows=1, cols=None):\n",
        "    with zipfile(dataset_input_zip_folder) as z:\n",
        "        with z.open(train_data_file_name) as f:\n",
        "            df = pd.read_csv(f, nrows = nbr_rows, usecols=cols)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiL-tyStcGG8"
      },
      "source": [
        "# Composit features\n",
        "In this section composit features are isolated.\n",
        "\n",
        "\n",
        "1.   The variables with multiple dimensions are referred to as composit features. Each composit feature is composed of its 60 dimensional features\n",
        "2.   The scaler variables are grouped together and referred to as scaler feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QQGYsBNdF0B"
      },
      "outputs": [],
      "source": [
        "# sample the data\n",
        "import re\n",
        "\n",
        "# parse columns' names of the input/output variables\n",
        "# input features are categorized as composit and scaler\n",
        "# composit ones are the with multiple dimensions\n",
        "# the scaler ones are grouped together\n",
        "\n",
        "df_submission_columns = read_dataset(dataset_input_zip_folder, submission_data_file_name, 0)\n",
        "\n",
        "targets = df_submission_columns.columns.to_list()\n",
        "targets.remove('sample_id')\n",
        "target_scalers_cols = targets\n",
        "target_composits_cols = list()\n",
        "\n",
        "target_composits = \"ptend_t,ptend_q0001,ptend_q0002,ptend_q0003,ptend_u,ptend_v\".split(\",\")\n",
        "\n",
        "all_elts_of_composit_targets = dict()\n",
        "for pattern in target_composits:\n",
        "    all_elts_of_composit_targets[pattern] = [x for x in targets if re.match(pattern + \"_[0-9]+$\",x)]\n",
        "    target_scalers_cols = [x for x in target_scalers_cols if x not in all_elts_of_composit_targets[pattern]]\n",
        "    target_composits_cols.extend(all_elts_of_composit_targets[pattern]) # keep a list of all columns\n",
        "\n",
        "# features\n",
        "df_train_columns = read_dataset(dataset_input_zip_folder, train_data_file_name, 0)\n",
        "\n",
        "features = [x for x in df_train_columns.columns.tolist() if x not in ['sample_id']+targets]\n",
        "feature_scalers_cols = features\n",
        "feature_composits_cols = list()\n",
        "\n",
        "feature_composits = \"state_t,state_q0001,state_q0002,state_q0003,state_u,state_v,pbuf_ozone,pbuf_CH4,pbuf_N2O\".split(\",\")\n",
        "\n",
        "all_elts_of_composit_features = dict()\n",
        "for pattern in feature_composits:\n",
        "    all_elts_of_composit_features[pattern] = [x for x in features if re.match(pattern + \"_[0-9]+$\",x)]\n",
        "    feature_scalers_cols = [x for x in feature_scalers_cols if x not in all_elts_of_composit_features[pattern]]\n",
        "    feature_composits_cols.extend(all_elts_of_composit_features[pattern])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLocYAREbaob"
      },
      "source": [
        "# Import PCs and target variables\n",
        "In the EDA, we transformed the inupt data into principal components. Below the PCs are loaded from parquet files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA2uXDA2dF0K",
        "outputId": "86e21557-a495-4e53-fd4a-3066d7599c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pcs of composit feature  state_t\n",
            "Loading pcs of composit feature  state_q0001\n",
            "Loading pcs of composit feature  state_q0002\n",
            "Loading pcs of composit feature  state_q0003\n",
            "Loading pcs of composit feature  state_u\n",
            "Loading pcs of composit feature  state_v\n",
            "Loading pcs of composit feature  pbuf_ozone\n",
            "Loading pcs of composit feature  pbuf_CH4\n",
            "Loading pcs of composit feature  pbuf_N2O\n"
          ]
        }
      ],
      "source": [
        "def load_data (root_dir, project_dir, file_name, feature_name):\n",
        "    df = pd.read_parquet(root_dir + project_dir + '/' + file_name)\n",
        "    df.columns = [feature_name + '_' + str(col) for col in df.columns]\n",
        "    return df\n",
        "\n",
        "\n",
        "df_train = dict()\n",
        "for feature_name in feature_composits:\n",
        "    print(\"Loading pcs of composit feature \", feature_name)\n",
        "    df_train[feature_name] = load_data(root_dir, project_working_dir, 'composit_feature_' + feature_name + '_df.parquet', feature_name)\n",
        "\n",
        "\n",
        "df_train[\"scaler\"] = load_data(root_dir, project_working_dir, 'scaler_features_df.parquet', 'scaler')\n",
        "\n",
        "df_output = load_data(root_dir, project_working_dir, 'outputs_df.parquet', '')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0RVUu7UhWl3"
      },
      "source": [
        "# Modeling Approach\n",
        "\n",
        "First define the custom R2 metric to measure the performance of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwrQ9aKW6oAH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define custom R-squared metric\n",
        "class R2Metric(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='r_squared', **kwargs):\n",
        "        super(R2Metric, self).__init__(name=name, **kwargs)\n",
        "        self.sse = self.add_weight(name='sse', initializer='zeros')\n",
        "        self.sst = self.add_weight(name='sst', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "        # Residual sum of squares (sse)\n",
        "        sse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "\n",
        "        # Total sum of squares (sst)\n",
        "        sst = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
        "\n",
        "        # Update the states\n",
        "        self.sse.assign_add(sse)\n",
        "        self.sst.assign_add(sst)\n",
        "\n",
        "    def result(self):\n",
        "        return 1 - (self.sse / (self.sst + tf.keras.backend.epsilon()))  # To prevent division by zero\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.sse.assign(0.0)\n",
        "        self.sst.assign(0.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKH5KSKX9k_s"
      },
      "source": [
        "## The Multi-Layer Perceptron (MLP) Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization"
      ],
      "metadata": {
        "id": "THScbh23spe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize > /dev/null\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Activation\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.initializers import RandomUniform\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "state_t_input = df_train['state_t'].to_numpy()\n",
        "state_q0001_input = df_train['state_q0001'].to_numpy()\n",
        "state_q0002_input = df_train['state_q0002'].to_numpy()\n",
        "state_q0003_input = df_train['state_q0003'].to_numpy()\n",
        "state_u_input = df_train['state_u'].to_numpy()\n",
        "state_v_input = df_train['state_v'].to_numpy()\n",
        "pbuf_ozone_input = df_train['pbuf_ozone'].to_numpy()\n",
        "pbuf_CH4_input = df_train['pbuf_CH4'].to_numpy()\n",
        "pbuf_N2O_input = df_train['pbuf_N2O'].to_numpy()\n",
        "scaler_input = df_train['scaler'].to_numpy()\n",
        "output_input = df_output.to_numpy()\n",
        "\n",
        "\n",
        "# Split Data into Training and Validation Sets\n",
        "state_t_train,state_t_val,\\\n",
        "state_q0001_train,state_q0001_val,\\\n",
        "state_q0002_train,state_q0002_val,\\\n",
        "state_q0003_train,state_q0003_val,\\\n",
        "state_u_train,state_u_val,\\\n",
        "state_v_train,state_v_val,\\\n",
        "pbuf_ozone_train,pbuf_ozone_val,\\\n",
        "pbuf_CH4_train,pbuf_CH4_val,\\\n",
        "pbuf_N2O_train,pbuf_N2O_val,\\\n",
        "scaler_train,scaler_val,output_train,output_val = train_test_split(state_t_input,\\\n",
        "                   state_q0001_input,\\\n",
        "                   state_q0002_input,\\\n",
        "                   state_q0003_input,\\\n",
        "                   state_u_input,\\\n",
        "                   state_v_input,\\\n",
        "                   pbuf_ozone_input,\\\n",
        "                   pbuf_CH4_input,\\\n",
        "                   pbuf_N2O_input,\\\n",
        "                   scaler_input,\\\n",
        "                   output_input,\\\n",
        "                   test_size=0.2, random_state=42)\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "# define learning rate reduction on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "pi2YVu0Vsth-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 9. Train the model with validation data\n",
        "def fit_model2(model, nbr_epochs=2, batch_size=32):\n",
        "    history = model.fit([state_t_train,\\\n",
        "                     state_q0001_train,\\\n",
        "                     state_q0002_train,\\\n",
        "                     state_q0003_train,\\\n",
        "                     state_u_train,\\\n",
        "                     state_v_train,\\\n",
        "                     pbuf_ozone_train,\\\n",
        "                     pbuf_CH4_train,\\\n",
        "                     pbuf_N2O_train,\\\n",
        "                     scaler_train], output_train,\\\n",
        "                    validation_data=([state_t_val,\\\n",
        "                     state_q0001_val,\\\n",
        "                     state_q0002_val,\\\n",
        "                     state_q0003_val,\\\n",
        "                     state_u_val,\\\n",
        "                     state_v_val,\\\n",
        "                     pbuf_ozone_val,\\\n",
        "                     pbuf_CH4_val,\\\n",
        "                     pbuf_N2O_val,\\\n",
        "                     scaler_val], output_val),\n",
        "                    epochs=nbr_epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
        "\n",
        "    val_loss, val_mse = model.evaluate([state_t_val,\\\n",
        "                     state_q0001_val,\\\n",
        "                     state_q0002_val,\\\n",
        "                     state_q0003_val,\\\n",
        "                     state_u_val,\\\n",
        "                     state_v_val,\\\n",
        "                     pbuf_ozone_val,\\\n",
        "                     pbuf_CH4_val,\\\n",
        "                     pbuf_N2O_val,\\\n",
        "                     scaler_val], output_val)\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "# Create a function to define and train a neural network model\n",
        "def create_and_train_nn(params):\n",
        "\n",
        "  inputs = dict()\n",
        "  for feature_name in df_train.keys():\n",
        "    inputs[feature_name] = Input(shape =(df_train[feature_name].shape[1],), name=feature_name)\n",
        "\n",
        "  # Define the uniform initializer of the weights\n",
        "  initializer = RandomUniform(minval=-0.1, maxval=0.1)\n",
        "\n",
        "\n",
        "  # input layer\n",
        "  input_layer = Concatenate()([inputs['state_t'],inputs['state_q0001'],inputs['state_q0002'],inputs['state_q0003'],inputs['state_u'],inputs['state_v'],inputs['pbuf_ozone'],inputs['pbuf_CH4'],inputs['pbuf_N2O'],inputs['scaler']])\n",
        "\n",
        "  # batch normalization layer\n",
        "  batch_norm_layer = BatchNormalization()(input_layer)\n",
        "\n",
        "  # 2 hidden layers\n",
        "  hidden_layer = Dense(units=params[3], activation=params[5], kernel_initializer=initializer)(batch_norm_layer)\n",
        "  hidden_layer = Dense(units=params[3] + len(feature_scalers_cols), activation=params[5], kernel_initializer=initializer)(hidden_layer)\n",
        "\n",
        "  # another batch normalization layer\n",
        "  #batch_norm_layer = tf.keras.layers.BatchNormalization()(hidden_layer)\n",
        "\n",
        "\n",
        "  # output layer\n",
        "  output_layer = Dense(units=df_output.shape[1], activation='linear', kernel_initializer=initializer)(hidden_layer)\n",
        "\n",
        "\n",
        "  # 7. Create the model\n",
        "  model = Model(inputs=[inputs[feature_name] for feature_name in df_train.keys()], outputs=output_layer)\n",
        "\n",
        "  # Compile the model with the custom R-squared metric\n",
        "  # tried adagrad but was not as good as adam\n",
        "  optimizer = Adam(learning_rate=params[0])\n",
        "  model.compile(optimizer=optimizer, loss='mse', metrics=[R2Metric()])\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "def create_and_train_nn2(params):\n",
        "  model = create_and_train_nn(params)\n",
        "  return fit_model2(model, params[1], params[2])\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "search_space = [\n",
        "    #Integer(1, 3, name='num_hidden_layers'),  # Number of hidden layers (1-3)\n",
        "    Real(1e-4, 1e-2, \"log-uniform\", name='learning_rate'),  # Learning rate (log scale)\n",
        "    #Real(0.0, 0.5, name='dropout_rate'),  # Dropout rate (0-50%)\n",
        "    Integer(50, 80, name='batch_size'),  # Batch size (16-128)\n",
        "    Integer(30, 50, name='epochs'), # Number of epochs (10-50)\n",
        "    Integer(df_output.shape[1], (df_output.shape[1]+len(feature_scalers_cols)), name='num_neurons'),  # Number of neurons per layer (32-256)\n",
        "    Integer(0, 2, name='num_hidden_layers'),  # Number of hidden layers (1-3),\n",
        "    Categorical(['relu', 'tanh', 'sigmoid'], name='activation')\n",
        "]\n",
        "\n",
        "def gpu2():\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "    print(\n",
        "        '\\n\\nThis error most likely means that this notebook is not '\n",
        "        'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "        'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    # Perform the optimization using Bayesian Optimization (GP-based optimization)\n",
        "    result = gp_minimize(\n",
        "      func=create_and_train_nn2,  # Objective function\n",
        "      dimensions=search_space,  # Hyperparameter space\n",
        "      n_calls=20,  # Number of iterations\n",
        "      random_state=42,  # Random state for reproducibility\n",
        "      verbose=True\n",
        "    )\n",
        "\n",
        "    # Get the best hyperparameters and print them\n",
        "    best_hyperparameters = result.x\n",
        "    print(\"Best hyperparameters:\", best_hyperparameters)\n",
        "\n",
        "#cpu()\n",
        "gpu2()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEliFBKAjSpe",
        "outputId": "488eb79d-3585-477e-ade1-fcf771036b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration No: 1 started. Evaluating function at random point.\n",
            "Epoch 1/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3ms/step - loss: 20.9641 - r_squared: 0.9689 - val_loss: 6.1217 - val_r_squared: 0.9910\n",
            "Epoch 2/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 8.8735 - r_squared: 0.9870 - val_loss: 5.9489 - val_r_squared: 0.9913\n",
            "Epoch 3/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 8.0636 - r_squared: 0.9882 - val_loss: 5.7701 - val_r_squared: 0.9915\n",
            "Epoch 4/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 7.6579 - r_squared: 0.9887 - val_loss: 6.1128 - val_r_squared: 0.9910\n",
            "Epoch 5/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 7.4757 - r_squared: 0.9890 - val_loss: 6.4441 - val_r_squared: 0.9906\n",
            "Epoch 6/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 7.3407 - r_squared: 0.9892 - val_loss: 5.9315 - val_r_squared: 0.9913\n",
            "Epoch 7/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 7.1881 - r_squared: 0.9894 - val_loss: 5.4151 - val_r_squared: 0.9921\n",
            "Epoch 8/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 7.0984 - r_squared: 0.9896 - val_loss: 5.8284 - val_r_squared: 0.9915\n",
            "Epoch 9/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 7.0267 - r_squared: 0.9897 - val_loss: 6.8333 - val_r_squared: 0.9900\n",
            "Epoch 10/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.9558 - r_squared: 0.9898 - val_loss: 5.2017 - val_r_squared: 0.9924\n",
            "Epoch 11/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.9533 - r_squared: 0.9898 - val_loss: 5.8244 - val_r_squared: 0.9915\n",
            "Epoch 12/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.9107 - r_squared: 0.9899 - val_loss: 7.0838 - val_r_squared: 0.9896\n",
            "Epoch 13/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.7977 - r_squared: 0.9900 - val_loss: 7.0671 - val_r_squared: 0.9896\n",
            "Epoch 14/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.8187 - r_squared: 0.9900 - val_loss: 5.7908 - val_r_squared: 0.9915\n",
            "Epoch 15/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.8004 - r_squared: 0.9900 - val_loss: 6.2243 - val_r_squared: 0.9909\n",
            "Epoch 16/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.7458 - r_squared: 0.9901 - val_loss: 4.9794 - val_r_squared: 0.9927\n",
            "Epoch 17/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.7058 - r_squared: 0.9902 - val_loss: 5.6848 - val_r_squared: 0.9917\n",
            "Epoch 18/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.7432 - r_squared: 0.9901 - val_loss: 5.1287 - val_r_squared: 0.9925\n",
            "Epoch 19/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.6737 - r_squared: 0.9902 - val_loss: 6.2012 - val_r_squared: 0.9909\n",
            "Epoch 20/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.6978 - r_squared: 0.9902 - val_loss: 4.8351 - val_r_squared: 0.9929\n",
            "Epoch 21/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.7089 - r_squared: 0.9902 - val_loss: 5.9169 - val_r_squared: 0.9913\n",
            "Epoch 22/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.6385 - r_squared: 0.9903 - val_loss: 5.0680 - val_r_squared: 0.9926\n",
            "Epoch 23/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.6749 - r_squared: 0.9902 - val_loss: 4.8395 - val_r_squared: 0.9929\n",
            "Epoch 24/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.6635 - r_squared: 0.9902 - val_loss: 5.5353 - val_r_squared: 0.9919\n",
            "Epoch 25/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.5931 - r_squared: 0.9903 - val_loss: 4.6967 - val_r_squared: 0.9931\n",
            "Epoch 26/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.6038 - r_squared: 0.9903 - val_loss: 5.6551 - val_r_squared: 0.9917\n",
            "Epoch 27/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.6181 - r_squared: 0.9903 - val_loss: 5.4225 - val_r_squared: 0.9921\n",
            "Epoch 28/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.5940 - r_squared: 0.9903 - val_loss: 5.3009 - val_r_squared: 0.9922\n",
            "Epoch 29/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.5407 - r_squared: 0.9904 - val_loss: 5.2085 - val_r_squared: 0.9924\n",
            "Epoch 30/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.5180 - r_squared: 0.9904 - val_loss: 5.0965 - val_r_squared: 0.9925\n",
            "Epoch 31/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.5114 - r_squared: 0.9904 - val_loss: 5.3407 - val_r_squared: 0.9922\n",
            "Epoch 32/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.5520 - r_squared: 0.9904 - val_loss: 6.0587 - val_r_squared: 0.9911\n",
            "Epoch 33/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.5300 - r_squared: 0.9904 - val_loss: 5.1129 - val_r_squared: 0.9925\n",
            "Epoch 34/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.5663 - r_squared: 0.9904 - val_loss: 5.2083 - val_r_squared: 0.9924\n",
            "Epoch 35/56\n",
            "\u001b[1m17392/17392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 6.4947 - r_squared: 0.9905 - val_loss: 5.7723 - val_r_squared: 0.9915\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 4.7060 - r_squared: 0.9931\n",
            "Iteration No: 1 ended. Evaluation done at random point.\n",
            "Time taken: 1483.2274\n",
            "Function value obtained: 4.6967\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "Epoch 1/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 116.5599 - r_squared: 0.8295 - val_loss: 7.1982 - val_r_squared: 0.9895\n",
            "Epoch 2/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 9.6994 - r_squared: 0.9857 - val_loss: 7.1385 - val_r_squared: 0.9895\n",
            "Epoch 3/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.6423 - r_squared: 0.9873 - val_loss: 6.8963 - val_r_squared: 0.9899\n",
            "Epoch 4/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.1444 - r_squared: 0.9880 - val_loss: 5.5753 - val_r_squared: 0.9918\n",
            "Epoch 5/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.9298 - r_squared: 0.9884 - val_loss: 5.1095 - val_r_squared: 0.9925\n",
            "Epoch 6/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.6845 - r_squared: 0.9887 - val_loss: 5.6411 - val_r_squared: 0.9917\n",
            "Epoch 7/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.5046 - r_squared: 0.9890 - val_loss: 5.2944 - val_r_squared: 0.9922\n",
            "Epoch 8/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.4375 - r_squared: 0.9891 - val_loss: 5.1292 - val_r_squared: 0.9925\n",
            "Epoch 9/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.3028 - r_squared: 0.9893 - val_loss: 4.9633 - val_r_squared: 0.9927\n",
            "Epoch 10/60\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.2341 - r_squared: 0.9894 - val_loss: 5.0571 - val_r_squared: 0.9926\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 7.1472 - r_squared: 0.9895\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 612.2557\n",
            "Function value obtained: 7.1982\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "Epoch 1/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - loss: 20.1821 - r_squared: 0.9704 - val_loss: 6.9922 - val_r_squared: 0.9898\n",
            "Epoch 2/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 9.0935 - r_squared: 0.9867 - val_loss: 6.9538 - val_r_squared: 0.9898\n",
            "Epoch 3/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 8.4329 - r_squared: 0.9876 - val_loss: 6.3565 - val_r_squared: 0.9907\n",
            "Epoch 4/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 8.1995 - r_squared: 0.9879 - val_loss: 6.2805 - val_r_squared: 0.9908\n",
            "Epoch 5/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 8.0036 - r_squared: 0.9883 - val_loss: 5.4850 - val_r_squared: 0.9920\n",
            "Epoch 6/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.8860 - r_squared: 0.9884 - val_loss: 6.0729 - val_r_squared: 0.9911\n",
            "Epoch 7/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.8330 - r_squared: 0.9885 - val_loss: 7.5604 - val_r_squared: 0.9889\n",
            "Epoch 8/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.7355 - r_squared: 0.9886 - val_loss: 6.3602 - val_r_squared: 0.9907\n",
            "Epoch 9/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.7167 - r_squared: 0.9887 - val_loss: 8.9359 - val_r_squared: 0.9869\n",
            "Epoch 10/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.6717 - r_squared: 0.9887 - val_loss: 5.7005 - val_r_squared: 0.9916\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 6.9829 - r_squared: 0.9898\n",
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 410.8275\n",
            "Function value obtained: 6.9922\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "Epoch 1/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3ms/step - loss: 90.9474 - r_squared: 0.8670 - val_loss: 11.1290 - val_r_squared: 0.9837\n",
            "Epoch 2/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 14.0063 - r_squared: 0.9794 - val_loss: 9.1593 - val_r_squared: 0.9866\n",
            "Epoch 3/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 11.2712 - r_squared: 0.9835 - val_loss: 7.8188 - val_r_squared: 0.9885\n",
            "Epoch 4/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 9.8110 - r_squared: 0.9856 - val_loss: 6.7920 - val_r_squared: 0.9900\n",
            "Epoch 5/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 9.0840 - r_squared: 0.9867 - val_loss: 6.6847 - val_r_squared: 0.9902\n",
            "Epoch 6/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 8.6817 - r_squared: 0.9872 - val_loss: 6.6327 - val_r_squared: 0.9903\n",
            "Epoch 7/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 8.4145 - r_squared: 0.9876 - val_loss: 6.4646 - val_r_squared: 0.9905\n",
            "Epoch 8/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 8.1546 - r_squared: 0.9880 - val_loss: 6.4128 - val_r_squared: 0.9906\n",
            "Epoch 9/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 7.9931 - r_squared: 0.9883 - val_loss: 6.6151 - val_r_squared: 0.9903\n",
            "Epoch 10/66\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 7.8948 - r_squared: 0.9884 - val_loss: 6.1647 - val_r_squared: 0.9910\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 11.1171 - r_squared: 0.9837\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 549.7983\n",
            "Function value obtained: 11.1290\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "Epoch 1/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 3ms/step - loss: 325.6969 - r_squared: 0.5225 - val_loss: 20.2600 - val_r_squared: 0.9703\n",
            "Epoch 2/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 19.4135 - r_squared: 0.9714 - val_loss: 9.8055 - val_r_squared: 0.9856\n",
            "Epoch 3/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 12.6978 - r_squared: 0.9813 - val_loss: 7.7360 - val_r_squared: 0.9887\n",
            "Epoch 4/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 10.8499 - r_squared: 0.9841 - val_loss: 7.0076 - val_r_squared: 0.9897\n",
            "Epoch 5/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 9.6894 - r_squared: 0.9858 - val_loss: 6.9780 - val_r_squared: 0.9898\n",
            "Epoch 6/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 9.0950 - r_squared: 0.9866 - val_loss: 5.9706 - val_r_squared: 0.9912\n",
            "Epoch 7/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 8.6832 - r_squared: 0.9873 - val_loss: 5.5688 - val_r_squared: 0.9918\n",
            "Epoch 8/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 8.3165 - r_squared: 0.9878 - val_loss: 5.5137 - val_r_squared: 0.9919\n",
            "Epoch 9/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2ms/step - loss: 8.1113 - r_squared: 0.9881 - val_loss: 5.5286 - val_r_squared: 0.9919\n",
            "Epoch 10/69\n",
            "\u001b[1m21053/21053\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - loss: 7.8522 - r_squared: 0.9884 - val_loss: 5.4337 - val_r_squared: 0.9920\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 20.3313 - r_squared: 0.9702\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 546.4746\n",
            "Function value obtained: 20.2601\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "Epoch 1/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3ms/step - loss: 48.8697 - r_squared: 0.9283 - val_loss: 7.7682 - val_r_squared: 0.9886\n",
            "Epoch 2/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 10.3773 - r_squared: 0.9848 - val_loss: 7.1526 - val_r_squared: 0.9895\n",
            "Epoch 3/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.9031 - r_squared: 0.9854 - val_loss: 7.2376 - val_r_squared: 0.9894\n",
            "Epoch 4/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.7175 - r_squared: 0.9857 - val_loss: 6.8198 - val_r_squared: 0.9900\n",
            "Epoch 5/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.7430 - r_squared: 0.9857 - val_loss: 6.6723 - val_r_squared: 0.9902\n",
            "Epoch 6/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.5788 - r_squared: 0.9859 - val_loss: 7.0347 - val_r_squared: 0.9897\n",
            "Epoch 7/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.5735 - r_squared: 0.9859 - val_loss: 6.6095 - val_r_squared: 0.9903\n",
            "Epoch 8/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.4964 - r_squared: 0.9860 - val_loss: 6.6541 - val_r_squared: 0.9902\n",
            "Epoch 9/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.4991 - r_squared: 0.9861 - val_loss: 6.8449 - val_r_squared: 0.9900\n",
            "Epoch 10/64\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.4121 - r_squared: 0.9862 - val_loss: 6.7972 - val_r_squared: 0.9900\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 7.8153 - r_squared: 0.9886\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 672.5624\n",
            "Function value obtained: 7.7682\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "Epoch 1/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3ms/step - loss: 361.7742 - r_squared: 0.4680 - val_loss: 35.6478 - val_r_squared: 0.9478\n",
            "Epoch 2/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2ms/step - loss: 28.5447 - r_squared: 0.9581 - val_loss: 12.1217 - val_r_squared: 0.9822\n",
            "Epoch 3/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 15.3057 - r_squared: 0.9775 - val_loss: 9.1863 - val_r_squared: 0.9865\n",
            "Epoch 4/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 12.4949 - r_squared: 0.9816 - val_loss: 7.7702 - val_r_squared: 0.9886\n",
            "Epoch 5/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 10.9933 - r_squared: 0.9839 - val_loss: 7.4149 - val_r_squared: 0.9891\n",
            "Epoch 6/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 10.1934 - r_squared: 0.9850 - val_loss: 7.4290 - val_r_squared: 0.9891\n",
            "Epoch 7/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 9.5342 - r_squared: 0.9860 - val_loss: 6.5317 - val_r_squared: 0.9904\n",
            "Epoch 8/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 9.1080 - r_squared: 0.9866 - val_loss: 6.5710 - val_r_squared: 0.9904\n",
            "Epoch 9/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 8.8272 - r_squared: 0.9870 - val_loss: 5.9537 - val_r_squared: 0.9913\n",
            "Epoch 10/57\n",
            "\u001b[1m22858/22858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 8.5626 - r_squared: 0.9874 - val_loss: 6.4016 - val_r_squared: 0.9906\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 35.7922 - r_squared: 0.9476\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 598.3081\n",
            "Function value obtained: 35.6481\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "Epoch 1/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3ms/step - loss: 58.2286 - r_squared: 0.9148 - val_loss: 8.7177 - val_r_squared: 0.9872\n",
            "Epoch 2/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 11.2612 - r_squared: 0.9835 - val_loss: 6.9953 - val_r_squared: 0.9897\n",
            "Epoch 3/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 9.4258 - r_squared: 0.9862 - val_loss: 7.9954 - val_r_squared: 0.9883\n",
            "Epoch 4/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.8923 - r_squared: 0.9869 - val_loss: 6.6956 - val_r_squared: 0.9902\n",
            "Epoch 5/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2ms/step - loss: 8.5440 - r_squared: 0.9875 - val_loss: 5.9444 - val_r_squared: 0.9913\n",
            "Epoch 6/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.2632 - r_squared: 0.9879 - val_loss: 6.4257 - val_r_squared: 0.9906\n",
            "Epoch 7/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.0872 - r_squared: 0.9881 - val_loss: 5.8142 - val_r_squared: 0.9915\n",
            "Epoch 8/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.8849 - r_squared: 0.9884 - val_loss: 5.5761 - val_r_squared: 0.9918\n",
            "Epoch 9/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.7608 - r_squared: 0.9886 - val_loss: 6.2160 - val_r_squared: 0.9909\n",
            "Epoch 10/62\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 7.6932 - r_squared: 0.9887 - val_loss: 5.4069 - val_r_squared: 0.9921\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 8.6970 - r_squared: 0.9873\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 610.1194\n",
            "Function value obtained: 8.7177\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "Epoch 1/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 3ms/step - loss: 105.1994 - r_squared: 0.8453 - val_loss: 6.3984 - val_r_squared: 0.9906\n",
            "Epoch 2/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 8.4499 - r_squared: 0.9876 - val_loss: 5.6868 - val_r_squared: 0.9917\n",
            "Epoch 3/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 7.6418 - r_squared: 0.9888 - val_loss: 5.3845 - val_r_squared: 0.9921\n",
            "Epoch 4/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - loss: 7.2576 - r_squared: 0.9894 - val_loss: 5.9049 - val_r_squared: 0.9913\n",
            "Epoch 5/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 7.0373 - r_squared: 0.9897 - val_loss: 5.0363 - val_r_squared: 0.9926\n",
            "Epoch 6/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.8325 - r_squared: 0.9900 - val_loss: 5.3884 - val_r_squared: 0.9921\n",
            "Epoch 7/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.7512 - r_squared: 0.9901 - val_loss: 5.2141 - val_r_squared: 0.9924\n",
            "Epoch 8/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.6168 - r_squared: 0.9903 - val_loss: 4.8946 - val_r_squared: 0.9928\n",
            "Epoch 9/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 6.5933 - r_squared: 0.9903 - val_loss: 4.9115 - val_r_squared: 0.9928\n",
            "Epoch 10/51\n",
            "\u001b[1m17022/17022\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3ms/step - loss: 6.4926 - r_squared: 0.9905 - val_loss: 6.0380 - val_r_squared: 0.9912\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 6.3688 - r_squared: 0.9907\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 466.4588\n",
            "Function value obtained: 6.3984\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 10 started. Evaluating function at random point.\n",
            "Epoch 1/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3ms/step - loss: 63.4211 - r_squared: 0.9068 - val_loss: 6.0109 - val_r_squared: 0.9912\n",
            "Epoch 2/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 8.4810 - r_squared: 0.9875 - val_loss: 6.1118 - val_r_squared: 0.9910\n",
            "Epoch 3/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 7.9352 - r_squared: 0.9884 - val_loss: 5.5557 - val_r_squared: 0.9919\n",
            "Epoch 4/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 7.6957 - r_squared: 0.9887 - val_loss: 5.3063 - val_r_squared: 0.9922\n",
            "Epoch 5/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 7.4333 - r_squared: 0.9891 - val_loss: 5.3398 - val_r_squared: 0.9922\n",
            "Epoch 6/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 7.3254 - r_squared: 0.9893 - val_loss: 5.4130 - val_r_squared: 0.9921\n",
            "Epoch 7/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2ms/step - loss: 7.2203 - r_squared: 0.9894 - val_loss: 5.1629 - val_r_squared: 0.9924\n",
            "Epoch 8/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3ms/step - loss: 7.1927 - r_squared: 0.9894 - val_loss: 5.1082 - val_r_squared: 0.9925\n",
            "Epoch 9/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 7.1032 - r_squared: 0.9896 - val_loss: 5.6515 - val_r_squared: 0.9917\n",
            "Epoch 10/60\n",
            "\u001b[1m19513/19513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - loss: 7.0827 - r_squared: 0.9896 - val_loss: 5.0963 - val_r_squared: 0.9925\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 5.9849 - r_squared: 0.9912\n",
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 521.9920\n",
            "Function value obtained: 6.0109\n",
            "Current minimum: 4.6967\n",
            "Iteration No: 11 started. Searching for the next optimal point.\n",
            "Epoch 1/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 3ms/step - loss: 35.0690 - r_squared: 0.9484 - val_loss: 6.2648 - val_r_squared: 0.9908\n",
            "Epoch 2/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 8.6344 - r_squared: 0.9873 - val_loss: 5.8032 - val_r_squared: 0.9915\n",
            "Epoch 3/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 7.7980 - r_squared: 0.9886 - val_loss: 5.6737 - val_r_squared: 0.9917\n",
            "Epoch 4/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 7.2883 - r_squared: 0.9893 - val_loss: 5.1066 - val_r_squared: 0.9925\n",
            "Epoch 5/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 7.0145 - r_squared: 0.9897 - val_loss: 4.8240 - val_r_squared: 0.9929\n",
            "Epoch 6/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 6.8223 - r_squared: 0.9900 - val_loss: 4.6597 - val_r_squared: 0.9932\n",
            "Epoch 7/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.6890 - r_squared: 0.9901 - val_loss: 4.9401 - val_r_squared: 0.9928\n",
            "Epoch 8/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.5265 - r_squared: 0.9904 - val_loss: 4.6357 - val_r_squared: 0.9932\n",
            "Epoch 9/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.4280 - r_squared: 0.9906 - val_loss: 4.7813 - val_r_squared: 0.9930\n",
            "Epoch 10/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.3299 - r_squared: 0.9907 - val_loss: 4.6682 - val_r_squared: 0.9932\n",
            "Epoch 11/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.2381 - r_squared: 0.9909 - val_loss: 5.4933 - val_r_squared: 0.9919\n",
            "Epoch 12/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.2146 - r_squared: 0.9909 - val_loss: 4.9840 - val_r_squared: 0.9927\n",
            "Epoch 13/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.1264 - r_squared: 0.9910 - val_loss: 4.4561 - val_r_squared: 0.9935\n",
            "Epoch 14/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.0950 - r_squared: 0.9911 - val_loss: 4.6357 - val_r_squared: 0.9932\n",
            "Epoch 15/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.0082 - r_squared: 0.9912 - val_loss: 4.5378 - val_r_squared: 0.9933\n",
            "Epoch 16/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 5.9700 - r_squared: 0.9912 - val_loss: 4.5348 - val_r_squared: 0.9934\n",
            "Epoch 17/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.9025 - r_squared: 0.9913 - val_loss: 4.9555 - val_r_squared: 0.9927\n",
            "Epoch 18/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.8336 - r_squared: 0.9914 - val_loss: 4.3685 - val_r_squared: 0.9936\n",
            "Epoch 19/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 5.7643 - r_squared: 0.9915 - val_loss: 4.6439 - val_r_squared: 0.9932\n",
            "Epoch 20/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.7759 - r_squared: 0.9915 - val_loss: 4.3735 - val_r_squared: 0.9936\n",
            "Epoch 21/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.7503 - r_squared: 0.9916 - val_loss: 4.7820 - val_r_squared: 0.9930\n",
            "Epoch 22/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.7322 - r_squared: 0.9916 - val_loss: 4.9482 - val_r_squared: 0.9927\n",
            "Epoch 23/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.7005 - r_squared: 0.9916 - val_loss: 4.5936 - val_r_squared: 0.9933\n",
            "Epoch 24/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.6554 - r_squared: 0.9917 - val_loss: 4.2709 - val_r_squared: 0.9937\n",
            "Epoch 25/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 5.6483 - r_squared: 0.9917 - val_loss: 4.5948 - val_r_squared: 0.9933\n",
            "Epoch 26/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 5.6105 - r_squared: 0.9918 - val_loss: 4.2762 - val_r_squared: 0.9937\n",
            "Epoch 27/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 5.5655 - r_squared: 0.9918 - val_loss: 4.3704 - val_r_squared: 0.9936\n",
            "Epoch 28/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.5547 - r_squared: 0.9918 - val_loss: 4.1741 - val_r_squared: 0.9939\n",
            "Epoch 29/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.5696 - r_squared: 0.9918 - val_loss: 4.2303 - val_r_squared: 0.9938\n",
            "Epoch 30/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.5427 - r_squared: 0.9919 - val_loss: 4.3451 - val_r_squared: 0.9936\n",
            "Epoch 31/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.5069 - r_squared: 0.9919 - val_loss: 4.5830 - val_r_squared: 0.9933\n",
            "Epoch 32/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.4606 - r_squared: 0.9920 - val_loss: 4.5628 - val_r_squared: 0.9933\n",
            "Epoch 33/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.4437 - r_squared: 0.9920 - val_loss: 4.4704 - val_r_squared: 0.9934\n",
            "Epoch 34/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 5.4761 - r_squared: 0.9920 - val_loss: 4.1805 - val_r_squared: 0.9939\n",
            "Epoch 35/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 5.4335 - r_squared: 0.9920 - val_loss: 4.4066 - val_r_squared: 0.9935\n",
            "Epoch 36/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 5.3939 - r_squared: 0.9921 - val_loss: 4.6207 - val_r_squared: 0.9932\n",
            "Epoch 37/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.4001 - r_squared: 0.9921 - val_loss: 4.4497 - val_r_squared: 0.9935\n",
            "Epoch 38/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 5.3601 - r_squared: 0.9921 - val_loss: 4.4600 - val_r_squared: 0.9935\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 4.1752 - r_squared: 0.9939\n",
            "Iteration No: 11 ended. Search finished for the next optimal point.\n",
            "Time taken: 1550.8718\n",
            "Function value obtained: 4.1741\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n",
            "Epoch 1/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - loss: 32.5327 - r_squared: 0.9523 - val_loss: 6.7856 - val_r_squared: 0.9901\n",
            "Epoch 2/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 8.4575 - r_squared: 0.9876 - val_loss: 6.5225 - val_r_squared: 0.9904\n",
            "Epoch 3/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 7.7178 - r_squared: 0.9887 - val_loss: 6.3054 - val_r_squared: 0.9908\n",
            "Epoch 4/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 7.2993 - r_squared: 0.9893 - val_loss: 5.0486 - val_r_squared: 0.9926\n",
            "Epoch 5/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.9548 - r_squared: 0.9898 - val_loss: 4.8938 - val_r_squared: 0.9928\n",
            "Epoch 6/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 6.8029 - r_squared: 0.9900 - val_loss: 4.7530 - val_r_squared: 0.9930\n",
            "Epoch 7/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 6.6353 - r_squared: 0.9903 - val_loss: 5.0138 - val_r_squared: 0.9927\n",
            "Epoch 8/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.4695 - r_squared: 0.9905 - val_loss: 4.9063 - val_r_squared: 0.9928\n",
            "Epoch 9/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.3407 - r_squared: 0.9907 - val_loss: 4.9666 - val_r_squared: 0.9927\n",
            "Epoch 10/64\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.2502 - r_squared: 0.9908 - val_loss: 4.9957 - val_r_squared: 0.9927\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 6.7317 - r_squared: 0.9901\n",
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 430.3292\n",
            "Function value obtained: 6.7856\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 13 started. Searching for the next optimal point.\n",
            "Epoch 1/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3ms/step - loss: 34.8404 - r_squared: 0.9491 - val_loss: 6.9066 - val_r_squared: 0.9899\n",
            "Epoch 2/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 8.6542 - r_squared: 0.9873 - val_loss: 6.0720 - val_r_squared: 0.9911\n",
            "Epoch 3/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 7.7703 - r_squared: 0.9886 - val_loss: 5.7349 - val_r_squared: 0.9916\n",
            "Epoch 4/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 7.2792 - r_squared: 0.9893 - val_loss: 5.6072 - val_r_squared: 0.9918\n",
            "Epoch 5/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 7.0183 - r_squared: 0.9897 - val_loss: 5.1053 - val_r_squared: 0.9925\n",
            "Epoch 6/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 6.8245 - r_squared: 0.9900 - val_loss: 4.7697 - val_r_squared: 0.9930\n",
            "Epoch 7/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.6955 - r_squared: 0.9902 - val_loss: 4.8951 - val_r_squared: 0.9928\n",
            "Epoch 8/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 6.5587 - r_squared: 0.9904 - val_loss: 5.0757 - val_r_squared: 0.9926\n",
            "Epoch 9/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.3711 - r_squared: 0.9906 - val_loss: 5.5622 - val_r_squared: 0.9918\n",
            "Epoch 10/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - loss: 6.3372 - r_squared: 0.9907 - val_loss: 4.6199 - val_r_squared: 0.9932\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 6.8959 - r_squared: 0.9899\n",
            "Iteration No: 13 ended. Search finished for the next optimal point.\n",
            "Time taken: 430.9706\n",
            "Function value obtained: 6.9066\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 14 started. Searching for the next optimal point.\n",
            "Epoch 1/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3ms/step - loss: 36.2603 - r_squared: 0.9466 - val_loss: 6.5933 - val_r_squared: 0.9903\n",
            "Epoch 2/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 8.6450 - r_squared: 0.9873 - val_loss: 5.9115 - val_r_squared: 0.9913\n",
            "Epoch 3/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 7.7575 - r_squared: 0.9886 - val_loss: 6.8053 - val_r_squared: 0.9900\n",
            "Epoch 4/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - loss: 7.3292 - r_squared: 0.9892 - val_loss: 4.9941 - val_r_squared: 0.9927\n",
            "Epoch 5/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - loss: 7.0330 - r_squared: 0.9897 - val_loss: 5.1212 - val_r_squared: 0.9925\n",
            "Epoch 6/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.8299 - r_squared: 0.9900 - val_loss: 5.4207 - val_r_squared: 0.9921\n",
            "Epoch 7/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.6885 - r_squared: 0.9902 - val_loss: 4.9859 - val_r_squared: 0.9927\n",
            "Epoch 8/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.5292 - r_squared: 0.9904 - val_loss: 4.8684 - val_r_squared: 0.9929\n",
            "Epoch 9/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.4600 - r_squared: 0.9905 - val_loss: 4.5924 - val_r_squared: 0.9933\n",
            "Epoch 10/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.3808 - r_squared: 0.9906 - val_loss: 4.6407 - val_r_squared: 0.9932\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 6.5152 - r_squared: 0.9905\n",
            "Iteration No: 14 ended. Search finished for the next optimal point.\n",
            "Time taken: 417.2168\n",
            "Function value obtained: 6.5933\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 15 started. Searching for the next optimal point.\n",
            "Epoch 1/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3ms/step - loss: 38.4104 - r_squared: 0.9436 - val_loss: 7.6559 - val_r_squared: 0.9888\n",
            "Epoch 2/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 8.7928 - r_squared: 0.9871 - val_loss: 6.1650 - val_r_squared: 0.9910\n",
            "Epoch 3/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.9041 - r_squared: 0.9884 - val_loss: 5.7668 - val_r_squared: 0.9915\n",
            "Epoch 4/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.4005 - r_squared: 0.9892 - val_loss: 5.6550 - val_r_squared: 0.9917\n",
            "Epoch 5/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.0772 - r_squared: 0.9896 - val_loss: 5.2604 - val_r_squared: 0.9923\n",
            "Epoch 6/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 6.9617 - r_squared: 0.9898 - val_loss: 5.3236 - val_r_squared: 0.9922\n",
            "Epoch 7/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 6.6942 - r_squared: 0.9902 - val_loss: 6.6676 - val_r_squared: 0.9902\n",
            "Epoch 8/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 6.6076 - r_squared: 0.9903 - val_loss: 4.8412 - val_r_squared: 0.9929\n",
            "Epoch 9/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 6.4907 - r_squared: 0.9905 - val_loss: 5.3141 - val_r_squared: 0.9922\n",
            "Epoch 10/80\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 6.3476 - r_squared: 0.9907 - val_loss: 4.8728 - val_r_squared: 0.9929\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 7.6110 - r_squared: 0.9889\n",
            "Iteration No: 15 ended. Search finished for the next optimal point.\n",
            "Time taken: 405.1985\n",
            "Function value obtained: 7.6559\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 16 started. Searching for the next optimal point.\n",
            "Epoch 1/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 3ms/step - loss: 75.1660 - r_squared: 0.8896 - val_loss: 7.2271 - val_r_squared: 0.9894\n",
            "Epoch 2/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 8.9505 - r_squared: 0.9869 - val_loss: 6.1667 - val_r_squared: 0.9910\n",
            "Epoch 3/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 8.3357 - r_squared: 0.9878 - val_loss: 5.6562 - val_r_squared: 0.9917\n",
            "Epoch 4/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2ms/step - loss: 7.9257 - r_squared: 0.9883 - val_loss: 6.0601 - val_r_squared: 0.9911\n",
            "Epoch 5/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 7.6909 - r_squared: 0.9887 - val_loss: 5.4315 - val_r_squared: 0.9920\n",
            "Epoch 6/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2ms/step - loss: 7.5917 - r_squared: 0.9889 - val_loss: 5.6708 - val_r_squared: 0.9917\n",
            "Epoch 7/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 7.5024 - r_squared: 0.9890 - val_loss: 5.0713 - val_r_squared: 0.9926\n",
            "Epoch 8/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 7.3983 - r_squared: 0.9891 - val_loss: 6.1003 - val_r_squared: 0.9911\n",
            "Epoch 9/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 7.2923 - r_squared: 0.9893 - val_loss: 6.3225 - val_r_squared: 0.9907\n",
            "Epoch 10/72\n",
            "\u001b[1m23530/23530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2ms/step - loss: 7.2755 - r_squared: 0.9893 - val_loss: 5.1421 - val_r_squared: 0.9925\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 7.1754 - r_squared: 0.9895\n",
            "Iteration No: 16 ended. Search finished for the next optimal point.\n",
            "Time taken: 593.1230\n",
            "Function value obtained: 7.2270\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 17 started. Searching for the next optimal point.\n",
            "Epoch 1/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3ms/step - loss: 22.6271 - r_squared: 0.9668 - val_loss: 6.4530 - val_r_squared: 0.9905\n",
            "Epoch 2/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.7597 - r_squared: 0.9857 - val_loss: 9.2685 - val_r_squared: 0.9864\n",
            "Epoch 3/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 9.0322 - r_squared: 0.9867 - val_loss: 5.7514 - val_r_squared: 0.9916\n",
            "Epoch 4/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 8.6877 - r_squared: 0.9872 - val_loss: 5.7703 - val_r_squared: 0.9915\n",
            "Epoch 5/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 8.3379 - r_squared: 0.9877 - val_loss: 5.7921 - val_r_squared: 0.9915\n",
            "Epoch 6/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2ms/step - loss: 8.2023 - r_squared: 0.9879 - val_loss: 7.4677 - val_r_squared: 0.9891\n",
            "Epoch 7/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2ms/step - loss: 8.0925 - r_squared: 0.9881 - val_loss: 6.7778 - val_r_squared: 0.9901\n",
            "Epoch 8/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 8.0123 - r_squared: 0.9882 - val_loss: 6.2979 - val_r_squared: 0.9908\n",
            "Epoch 9/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 7.8577 - r_squared: 0.9884 - val_loss: 5.4160 - val_r_squared: 0.9921\n",
            "Epoch 10/80\n",
            "\u001b[1m26667/26667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - loss: 7.8583 - r_squared: 0.9885 - val_loss: 6.7606 - val_r_squared: 0.9901\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - loss: 6.4433 - r_squared: 0.9906\n",
            "Iteration No: 17 ended. Search finished for the next optimal point.\n",
            "Time taken: 665.5633\n",
            "Function value obtained: 6.4530\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 18 started. Searching for the next optimal point.\n",
            "Epoch 1/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3ms/step - loss: 22.7316 - r_squared: 0.9667 - val_loss: 5.9718 - val_r_squared: 0.9912\n",
            "Epoch 2/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 8.6162 - r_squared: 0.9873 - val_loss: 5.3699 - val_r_squared: 0.9921\n",
            "Epoch 3/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.8254 - r_squared: 0.9885 - val_loss: 5.2669 - val_r_squared: 0.9923\n",
            "Epoch 4/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.3682 - r_squared: 0.9891 - val_loss: 5.0765 - val_r_squared: 0.9926\n",
            "Epoch 5/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.1611 - r_squared: 0.9895 - val_loss: 4.9727 - val_r_squared: 0.9927\n",
            "Epoch 6/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 7.0384 - r_squared: 0.9897 - val_loss: 5.7904 - val_r_squared: 0.9915\n",
            "Epoch 7/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.9186 - r_squared: 0.9899 - val_loss: 5.1885 - val_r_squared: 0.9924\n",
            "Epoch 8/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.8256 - r_squared: 0.9900 - val_loss: 4.9863 - val_r_squared: 0.9927\n",
            "Epoch 9/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.7374 - r_squared: 0.9901 - val_loss: 4.7789 - val_r_squared: 0.9930\n",
            "Epoch 10/61\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - loss: 6.6192 - r_squared: 0.9903 - val_loss: 4.7946 - val_r_squared: 0.9930\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 5.9663 - r_squared: 0.9913\n",
            "Iteration No: 18 ended. Search finished for the next optimal point.\n",
            "Time taken: 417.5571\n",
            "Function value obtained: 5.9718\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 19 started. Searching for the next optimal point.\n",
            "Epoch 1/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3ms/step - loss: 21.0214 - r_squared: 0.9693 - val_loss: 6.7178 - val_r_squared: 0.9902\n",
            "Epoch 2/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 9.8324 - r_squared: 0.9855 - val_loss: 6.4665 - val_r_squared: 0.9905\n",
            "Epoch 3/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 9.1627 - r_squared: 0.9865 - val_loss: 5.8923 - val_r_squared: 0.9914\n",
            "Epoch 4/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.7990 - r_squared: 0.9871 - val_loss: 6.3609 - val_r_squared: 0.9907\n",
            "Epoch 5/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.6071 - r_squared: 0.9874 - val_loss: 5.7405 - val_r_squared: 0.9916\n",
            "Epoch 6/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.3802 - r_squared: 0.9877 - val_loss: 7.8068 - val_r_squared: 0.9886\n",
            "Epoch 7/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.3381 - r_squared: 0.9877 - val_loss: 5.4916 - val_r_squared: 0.9920\n",
            "Epoch 8/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.2263 - r_squared: 0.9880 - val_loss: 5.8659 - val_r_squared: 0.9914\n",
            "Epoch 9/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.2058 - r_squared: 0.9880 - val_loss: 5.7689 - val_r_squared: 0.9915\n",
            "Epoch 10/80\n",
            "\u001b[1m24243/24243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 2ms/step - loss: 8.1194 - r_squared: 0.9881 - val_loss: 7.4911 - val_r_squared: 0.9890\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 6.6701 - r_squared: 0.9902\n",
            "Iteration No: 19 ended. Search finished for the next optimal point.\n",
            "Time taken: 615.7417\n",
            "Function value obtained: 6.7178\n",
            "Current minimum: 4.1741\n",
            "Iteration No: 20 started. Searching for the next optimal point.\n",
            "Epoch 1/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 3ms/step - loss: 21.8453 - r_squared: 0.9680 - val_loss: 6.5772 - val_r_squared: 0.9904\n",
            "Epoch 2/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 8.6583 - r_squared: 0.9873 - val_loss: 5.6528 - val_r_squared: 0.9917\n",
            "Epoch 3/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 7.8406 - r_squared: 0.9885 - val_loss: 5.7374 - val_r_squared: 0.9916\n",
            "Epoch 4/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 7.4875 - r_squared: 0.9890 - val_loss: 6.5868 - val_r_squared: 0.9903\n",
            "Epoch 5/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 7.2713 - r_squared: 0.9893 - val_loss: 5.3041 - val_r_squared: 0.9922\n",
            "Epoch 6/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 7.1322 - r_squared: 0.9895 - val_loss: 5.4086 - val_r_squared: 0.9921\n",
            "Epoch 7/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 7.0148 - r_squared: 0.9897 - val_loss: 5.3094 - val_r_squared: 0.9922\n",
            "Epoch 8/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.9587 - r_squared: 0.9898 - val_loss: 5.2600 - val_r_squared: 0.9923\n",
            "Epoch 9/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.8853 - r_squared: 0.9899 - val_loss: 5.2764 - val_r_squared: 0.9923\n",
            "Epoch 10/50\n",
            "\u001b[1m16000/16000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step - loss: 6.8099 - r_squared: 0.9900 - val_loss: 4.9689 - val_r_squared: 0.9927\n",
            "\u001b[1m6250/6250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 6.5604 - r_squared: 0.9904\n",
            "Iteration No: 20 ended. Search finished for the next optimal point.\n",
            "Time taken: 417.3327\n",
            "Function value obtained: 6.5772\n",
            "Current minimum: 4.1741\n",
            "Best hyperparameters: [0.0008468986729585612, 80, 50, 369, 2, 'relu']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 8877088,
          "sourceId": 56537,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}